  0%|                                                                                                                                                         | 0/10000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/wenhan/Projects/LISA/model/llava_new/LLaVA/llava/train/train.py", line 1151, in <module>
    train()
  File "/home/wenhan/Projects/LISA/model/llava_new/LLaVA/llava/train/train.py", line 1112, in train
    trainer.train()
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wenhan/anaconda3/envs/llava_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wenhan/Projects/LISA/model/llava_new/LLaVA/llava/train/train.py", line 889, in __getitem__
    return self._dataset[i]
  File "/home/wenhan/Projects/LISA/model/llava_new/LLaVA/llava/train/train.py", line 746, in __getitem__
    image = _postprocess_image(sample["img_content"], self._data_args)
  File "/home/wenhan/Projects/LISA/model/llava_new/LLaVA/llava/train/train.py", line 669, in _postprocess_image
    return torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0
RuntimeError: Could not infer dtype of JpegImageFile